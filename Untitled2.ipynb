{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T19:25:29.189187Z",
     "start_time": "2020-06-12T19:25:28.895886Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        \n",
    "        \n",
    "        self.encoder=nn.ModuleList([\n",
    "            nn.Conv1d(1,8,8,4,0,dilation=2),nn.BatchNorm1d(8), nn.ReLU(),\n",
    "            nn.Conv1d(8,64,8,4,0,dilation=2),nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Conv1d(64,128,8,4,0,dilation=2),nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Conv1d(128,256,4,2,0,dilation=1),nn.BatchNorm1d(256), nn.ReLU(),\n",
    "            nn.Conv1d(256,256,4,2,0,dilation=1), nn.BatchNorm1d(256),nn.ReLU(),  \n",
    "        ])\n",
    "        self.meanL=nn.Sequential(\n",
    "            nn.Linear(256,256),nn.BatchNorm1d(256),nn.ReLU(),\n",
    "            nn.Linear(256,256),nn.BatchNorm1d(256),nn.ReLU(),\n",
    "            nn.Linear(256,128),nn.BatchNorm1d(128),nn.ReLU(),\n",
    "            nn.Linear(128,128),nn.BatchNorm1d(128),nn.ReLU(),\n",
    "            nn.Linear(128,128),nn.BatchNorm1d(128),nn.ReLU(),\n",
    "            nn.Linear(128,127),nn.BatchNorm1d(127),nn.ReLU()\n",
    "        )\n",
    "        self.sigmaL=nn.Sequential(\n",
    "            nn.Linear(256,256),nn.BatchNorm1d(256),nn.ReLU(),\n",
    "            nn.Linear(256,256),nn.BatchNorm1d(256),nn.ReLU(),\n",
    "            nn.Linear(256,128),nn.BatchNorm1d(128),nn.ReLU(),\n",
    "            nn.Linear(128,128),nn.BatchNorm1d(128),nn.ReLU(),\n",
    "            nn.Linear(128,128),nn.BatchNorm1d(128),nn.ReLU(),\n",
    "            nn.Linear(128,127),nn.BatchNorm1d(127),nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.LinDecoder=nn.Sequential(\n",
    "            nn.Linear(128,128),nn.BatchNorm1d(128),nn.ReLU(),\n",
    "            nn.Linear(128,128),nn.BatchNorm1d(128),nn.ReLU(),\n",
    "            nn.Linear(128,256),nn.BatchNorm1d(256),nn.ReLU(),\n",
    "            nn.Linear(256,256),nn.BatchNorm1d(256),nn.ReLU(),\n",
    "            nn.Linear(256,256),nn.BatchNorm1d(256),nn.ReLU(),\n",
    "            nn.Linear(256,512),nn.BatchNorm1d(512),nn.ReLU(),\n",
    "            nn.Linear(512,512),nn.BatchNorm1d(512),nn.ReLU(),\n",
    "            nn.Linear(512,512),nn.Sigmoid()\n",
    "        )\n",
    "        self.up=nn.Upsample(scale_factor=2)\n",
    "        self.UpDec=nn.Sequential(\n",
    "            nn.Linear(1024,1024),nn.ReLU(),\n",
    "            nn.Linear(1024,1024),nn.ReLU()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def sample_latent(self,x,cl):\n",
    "        mean=self.meanL(x)\n",
    "        sigma=self.sigmaL(x)\n",
    "        sigma=torch.sqrt(torch.exp(sigma))\n",
    "        self.mean=mean\n",
    "        self.sigma=sigma\n",
    "        eps = torch.distributions.normal.Normal(0, 1).sample(sample_shape=sigma.size())\n",
    "        z=mean+sigma*Variable(eps,requires_grad=False).cuda()\n",
    "        z=torch.cat((z,cl),dim=1)\n",
    "        return z\n",
    "    \n",
    "    def forward(self,x):\n",
    "        cl=x[0:x.shape[0],0,-1].view(x.shape[0],1)\n",
    "        x=x[0:x.shape[0],0,0:1024].view(x.shape[0],1,1024)\n",
    "\n",
    "        for conv in self.encoder:\n",
    "            x=conv(x)\n",
    "\n",
    "        x=x.view(x.shape[0],256)\n",
    "        z=self.sample_latent(x,cl)\n",
    "\n",
    "        \n",
    "        \n",
    "        x=self.LinDecoder(z)\n",
    "        x=x.view(x.shape[0],1,512)\n",
    "        x=self.up(x)\n",
    "        x=self.UpDec(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T19:25:38.701486Z",
     "start_time": "2020-06-12T19:25:34.447698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples In flute\n",
      "Collecting Samples In bass\n",
      "Collecting Samples In vocal\n",
      "Collecting Samples In mallet\n",
      "Collecting Samples In keyboard\n",
      "Collecting Samples In string\n",
      "Collecting Samples In brass\n",
      "Collecting Samples In organ\n",
      "Collecting Samples In reed\n",
      "Collecting Samples In guitar\n",
      "Current Samples:  1240\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import load_dataset,myspec\n",
    "from os import listdir\n",
    "import math\n",
    "dataloader=load_dataset(samples=2)\n",
    "\n",
    "trainset=DataLoader(dataloader, batch_size=62, shuffle=False,drop_last=True, num_workers=4)\n",
    "vae=AutoEncoder().cuda()\n",
    "optimizer = optim.Adam(vae.parameters(),lr=1e-3)\n",
    "\n",
    "crit=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T19:25:47.584381Z",
     "start_time": "2020-06-12T19:25:44.823379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1119002252817154\n",
      "0.08301513642072678\n",
      "0.13044005632400513\n",
      "0.21896444261074066\n",
      "0.205958753824234\n"
     ]
    }
   ],
   "source": [
    "num_epochs=5\n",
    "for epoch in range(num_epochs):\n",
    "    for i in trainset:\n",
    "        x=Variable(i).cuda()\n",
    "        y=vae(x)\n",
    "        loss=crit(y,x[:,:,0:1024])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T19:26:36.193604Z",
     "start_time": "2020-06-12T19:26:36.117042Z"
    }
   },
   "outputs": [],
   "source": [
    "newstate={}\n",
    "for i in vae.state_dict():\n",
    "    try:\n",
    "        newstate[i]=checkpoint[i]\n",
    "    except:\n",
    "        newstate[i]=vae.state_dict()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T19:27:20.532690Z",
     "start_time": "2020-06-12T19:27:20.467141Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(newstate,'../wavenet/Upsave.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T19:26:14.812938Z",
     "start_time": "2020-06-12T19:26:14.770467Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../wavenet/batchMSE.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T19:26:56.457249Z",
     "start_time": "2020-06-12T19:26:56.441328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.0.weight\n",
      "encoder.0.bias\n",
      "encoder.1.weight\n",
      "encoder.1.bias\n",
      "encoder.1.running_mean\n",
      "encoder.1.running_var\n",
      "encoder.1.num_batches_tracked\n",
      "encoder.3.weight\n",
      "encoder.3.bias\n",
      "encoder.4.weight\n",
      "encoder.4.bias\n",
      "encoder.4.running_mean\n",
      "encoder.4.running_var\n",
      "encoder.4.num_batches_tracked\n",
      "encoder.6.weight\n",
      "encoder.6.bias\n",
      "encoder.7.weight\n",
      "encoder.7.bias\n",
      "encoder.7.running_mean\n",
      "encoder.7.running_var\n",
      "encoder.7.num_batches_tracked\n",
      "encoder.9.weight\n",
      "encoder.9.bias\n",
      "encoder.10.weight\n",
      "encoder.10.bias\n",
      "encoder.10.running_mean\n",
      "encoder.10.running_var\n",
      "encoder.10.num_batches_tracked\n",
      "encoder.12.weight\n",
      "encoder.12.bias\n",
      "encoder.13.weight\n",
      "encoder.13.bias\n",
      "encoder.13.running_mean\n",
      "encoder.13.running_var\n",
      "encoder.13.num_batches_tracked\n",
      "meanL.0.weight\n",
      "meanL.0.bias\n",
      "meanL.1.weight\n",
      "meanL.1.bias\n",
      "meanL.1.running_mean\n",
      "meanL.1.running_var\n",
      "meanL.1.num_batches_tracked\n",
      "meanL.3.weight\n",
      "meanL.3.bias\n",
      "meanL.4.weight\n",
      "meanL.4.bias\n",
      "meanL.4.running_mean\n",
      "meanL.4.running_var\n",
      "meanL.4.num_batches_tracked\n",
      "meanL.6.weight\n",
      "meanL.6.bias\n",
      "meanL.7.weight\n",
      "meanL.7.bias\n",
      "meanL.7.running_mean\n",
      "meanL.7.running_var\n",
      "meanL.7.num_batches_tracked\n",
      "meanL.9.weight\n",
      "meanL.9.bias\n",
      "meanL.10.weight\n",
      "meanL.10.bias\n",
      "meanL.10.running_mean\n",
      "meanL.10.running_var\n",
      "meanL.10.num_batches_tracked\n",
      "meanL.12.weight\n",
      "meanL.12.bias\n",
      "meanL.13.weight\n",
      "meanL.13.bias\n",
      "meanL.13.running_mean\n",
      "meanL.13.running_var\n",
      "meanL.13.num_batches_tracked\n",
      "meanL.15.weight\n",
      "meanL.15.bias\n",
      "meanL.16.weight\n",
      "meanL.16.bias\n",
      "meanL.16.running_mean\n",
      "meanL.16.running_var\n",
      "meanL.16.num_batches_tracked\n",
      "sigmaL.0.weight\n",
      "sigmaL.0.bias\n",
      "sigmaL.1.weight\n",
      "sigmaL.1.bias\n",
      "sigmaL.1.running_mean\n",
      "sigmaL.1.running_var\n",
      "sigmaL.1.num_batches_tracked\n",
      "sigmaL.3.weight\n",
      "sigmaL.3.bias\n",
      "sigmaL.4.weight\n",
      "sigmaL.4.bias\n",
      "sigmaL.4.running_mean\n",
      "sigmaL.4.running_var\n",
      "sigmaL.4.num_batches_tracked\n",
      "sigmaL.6.weight\n",
      "sigmaL.6.bias\n",
      "sigmaL.7.weight\n",
      "sigmaL.7.bias\n",
      "sigmaL.7.running_mean\n",
      "sigmaL.7.running_var\n",
      "sigmaL.7.num_batches_tracked\n",
      "sigmaL.9.weight\n",
      "sigmaL.9.bias\n",
      "sigmaL.10.weight\n",
      "sigmaL.10.bias\n",
      "sigmaL.10.running_mean\n",
      "sigmaL.10.running_var\n",
      "sigmaL.10.num_batches_tracked\n",
      "sigmaL.12.weight\n",
      "sigmaL.12.bias\n",
      "sigmaL.13.weight\n",
      "sigmaL.13.bias\n",
      "sigmaL.13.running_mean\n",
      "sigmaL.13.running_var\n",
      "sigmaL.13.num_batches_tracked\n",
      "sigmaL.15.weight\n",
      "sigmaL.15.bias\n",
      "sigmaL.16.weight\n",
      "sigmaL.16.bias\n",
      "sigmaL.16.running_mean\n",
      "sigmaL.16.running_var\n",
      "sigmaL.16.num_batches_tracked\n",
      "LinDecoder.0.weight\n",
      "LinDecoder.0.bias\n",
      "LinDecoder.1.weight\n",
      "LinDecoder.1.bias\n",
      "LinDecoder.1.running_mean\n",
      "LinDecoder.1.running_var\n",
      "LinDecoder.1.num_batches_tracked\n",
      "LinDecoder.3.weight\n",
      "LinDecoder.3.bias\n",
      "LinDecoder.4.weight\n",
      "LinDecoder.4.bias\n",
      "LinDecoder.4.running_mean\n",
      "LinDecoder.4.running_var\n",
      "LinDecoder.4.num_batches_tracked\n",
      "LinDecoder.6.weight\n",
      "LinDecoder.6.bias\n",
      "LinDecoder.7.weight\n",
      "LinDecoder.7.bias\n",
      "LinDecoder.7.running_mean\n",
      "LinDecoder.7.running_var\n",
      "LinDecoder.7.num_batches_tracked\n",
      "LinDecoder.9.weight\n",
      "LinDecoder.9.bias\n",
      "LinDecoder.10.weight\n",
      "LinDecoder.10.bias\n",
      "LinDecoder.10.running_mean\n",
      "LinDecoder.10.running_var\n",
      "LinDecoder.10.num_batches_tracked\n",
      "LinDecoder.12.weight\n",
      "LinDecoder.12.bias\n",
      "LinDecoder.13.weight\n",
      "LinDecoder.13.bias\n",
      "LinDecoder.13.running_mean\n",
      "LinDecoder.13.running_var\n",
      "LinDecoder.13.num_batches_tracked\n",
      "LinDecoder.15.weight\n",
      "LinDecoder.15.bias\n",
      "LinDecoder.16.weight\n",
      "LinDecoder.16.bias\n",
      "LinDecoder.16.running_mean\n",
      "LinDecoder.16.running_var\n",
      "LinDecoder.16.num_batches_tracked\n",
      "LinDecoder.18.weight\n",
      "LinDecoder.18.bias\n",
      "LinDecoder.19.weight\n",
      "LinDecoder.19.bias\n",
      "LinDecoder.19.running_mean\n",
      "LinDecoder.19.running_var\n",
      "LinDecoder.19.num_batches_tracked\n",
      "LinDecoder.21.weight\n",
      "LinDecoder.21.bias\n",
      "UpDec.0.weight\n",
      "UpDec.0.bias\n",
      "UpDec.2.weight\n",
      "UpDec.2.bias\n"
     ]
    }
   ],
   "source": [
    "for i in newstate:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
